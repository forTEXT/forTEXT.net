{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "761dc922",
   "metadata": {},
   "source": [
    "# forTEXT-Lerneihneit word2vec\n",
    "\n",
    "Diese Lerneinheit zeigt Ihnen schrittweise, wie Sie mit Gensim ein word2vec-Modell erstellen, Abfragen ausführen und Visualisierungen erhalten können. Vor jeder Code-Zeile finden Sie eine kurze Erklärung des nächsten Schrittes. Innerhalb der Code-Boxen finden Sie zum Teil Kommentare, die mit # als solche gekennzeichnet sind. In diesen Kommentaren finden Sie Erklärungen zu einzelnen Aspekten des Codes.\n",
    "\n",
    "Klicken Sie nun in die nächste Zeile, sodass ihr Cursor dort erscheint. Klicken Sie dann oben im Menü auf \"Run\", damit Ihnen Ergebnisse direkt unterhalb der Code-Zeilen in diesem Notebook angezeigt werden. Sobald in den eckigen Klammern links eine Zahl erscheint, wissen Sie, dass der Arbeitsschritt vom Computer abgeschlossen wurde. Wenn ein Schritt etwas länger dauert, so erscheint in den eckigen Klammern ein Asterisk (*). Sie erkennen daran, dass Ihr Computer einen Vorgang noch nicht abgeschlossen hat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea4c6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf73bbc",
   "metadata": {},
   "source": [
    "## Die Basis-Einstellungen laden\n",
    "\n",
    "Klicken Sie nun in die nächste Zeile, sodass Ihr Cursor dort erscheint. Um die Basiseinstellungen zu laden, klicken Sie dann oben im Menü auf \"Run\". Die Basiseinstellungen bedeuten, dass die Vektorgröße bei 100 Dimensionen liegt und dass von einem Wort immer 5 Wörter, die davor und 5 Wörter, die danach stehen als Kontext berücksichtigt werden. Außerdem werden die Wörter so umgeschrieben, dass im gesamten Korpus nur noch Kleinbuchstaben vorkommen (lowercasig). Mehr über die Standardeinstellungen für word2vec in Gensim erfahren Sie im Methodenbeitrag (Schumacher und Uglanova 2022: https://fortext.net/routinen/methoden/word2vec).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e95b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50082eb7",
   "metadata": {},
   "source": [
    "## Gensim laden\n",
    "\n",
    "Im nächsten Schritt werden wir zwei Dinge laden:\n",
    "\n",
    "1. Das Gensim-Package\n",
    "2. Das im eigenen Ordnersystem abgelegte Textkorpus\n",
    "\n",
    "Bitte ändern Sie nun in der Zeile\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">corpus_path = datapath('/Users/mareikeschumacher/Desktop/Goethe_Corpus/Goethe.cor')\n",
    "</div>\n",
    "\n",
    "den Dateipfad und ersetzen ihn durch die Benennung in Ihrem eigenen Ordner-System. Haben Sie z.B. das von uns vorbereitete Goethe-Korpus in Ihrem Downloads-Ordner abgelegt, so wird Ihr Dateipfad wahrscheinlich so ähnlich lauten wie:\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Beispiel:</b> corpus_path = datapath('/Users/Ihrname/Downloads/Goethe.cor')\n",
    "</div>\n",
    "\n",
    "Wie Sie ein eigenes Korpus so aufbereiten, dass es in ein word2vec-Modell umgewandelt werden kann, erfahren Sie auf unserer Webseite unter: https://fortext.net/routinen/lerneinheiten/word2vec-mit-gensim.\n",
    "\n",
    "Ist der Dateiname angepasst, so klicken Sie in die unten stehende Code-Box, sodass Ihr Cursor dort erscheint. Klicken Sie dann auf \"Run\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e435c0de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.test.utils import datapath\n",
    "from gensim import utils\n",
    "\n",
    "class MyCorpus:\n",
    "    \"\"\"An iterator that yields sentences (lists of str).\"\"\"\n",
    "\n",
    "    def __iter__(self):\n",
    "        corpus_path = datapath('/Users/mareikeschumacher/Desktop/Goethe_Corpus/Goethe.cor')\n",
    "        for line in open(corpus_path):\n",
    "            # Bedenken Sie, dass in Ihrem Korpus-Dokument jedes Werk eine Zeile einnehmen muss.\n",
    "            yield utils.simple_preprocess(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb1693d7",
   "metadata": {},
   "source": [
    "## word2vec-Modell trainieren\n",
    "\n",
    "Nun sind Sie so weit, dass das word2vec-Modell von Ihrem Korpus trainiert werden kann. Klicken Sie nun in die nächste Box, sodass Ihr Cursor dort erscheint. Wenn Sie anschließend auf \"Run\" klicken, so wird Ihre Modell trainiert. Ist der Vorgang abgeschlossen, so werden technische Informationen zum Modelltraining in einer roten Box unter dem Code angezeigt. Diese Box ist immer rot, Sie müssen also nicht befürchten, dass hier ein Fehler passiert ist. Sollte doch einmal ein Fehler aufkommen, so wird dieser als \"Error\" angezeigt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a625b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.models\n",
    "\n",
    "sentences = MyCorpus()\n",
    "model = gensim.models.Word2Vec(sentences=sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9841e355",
   "metadata": {},
   "source": [
    "## Speichern des word2vec-Modells in einem temporären Dateipfad\n",
    "\n",
    "Ihr Modell ist nun im Arbeitsspeicher abgelegt und Sie können Abfragen durchführen und Visualisierungen erstellen. Schließen Sie allerdings diese Sitzung, so wird das Modell nicht gespeichert. Um später noch einmal auf Ihr Modell zugreifen zu können oder um es mit anderen teilen zu können, legen Sie es am besten in einem temporären Dateipfad ab. Ein temporärer Dateipfad ist hier eine gute Wahl, weil Sie ihn bei neuen Trainings wieder überschreiben können und so nicht automatisch viele word2vec-Modelle auf Ihrem Computer ablegen. Diese können nämlich sehr groß werden und Ihnen viel Speicherplatz rauben. Vergessen Sie aber nicht, ein Modell, das Sie langfristig nutzen möchten, an einen anderen Speicherort zu verschieben. \n",
    "\n",
    "Klicken Sie nun in die unten stehende Box, sodass Ihr Cursor dort erscheint. Klicken Sie dann auf \"Run\". Achtung: Auch hier wird sich wieder eine rot unterlegte Box mit Informationen zu dem Vorgang zeigen. Wieder bedeutet dies nicht, dass dabei ein Fehler passiert ist. In der Box finden Sie auch den genauen Dateipfad, unter dem Sie ihr Modell nun in Ihrem Ordner-System finden können."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a04d4c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "\n",
    "with tempfile.NamedTemporaryFile(prefix='gensim-model-', delete=False) as tmp:\n",
    "    temporary_filepath = tmp.name\n",
    "    model.save(temporary_filepath)\n",
    "    \n",
    "    # Ihr Modell ist nun in dem temporären Dateipfad abgelegt.\n",
    "    # Sie können es kopieren und an einem anderen Ort speichern oder mit anderen teilen.\n",
    "    \n",
    "    # Um das im temporären Dateipfad abgelegte Modell zu laden, können Sie diese Code-Zeile nutzen:\n",
    "    \n",
    "    new_model = gensim.models.Word2Vec.load(temporary_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cdb69bd",
   "metadata": {},
   "source": [
    "## Abfragen stellen\n",
    "\n",
    "### Ähnliche Wörter für ein Zielwort finden\n",
    "\n",
    "Sie haben nun Ihr word2vec-Modell trainiert und gespeichert. Sie können jetzt abfragen erstellen und so herausfinden, welche Wörter in einem ähnlichen Kontext verwendet werden, wie ein Zielwort, für das Sie sich besonders interessieren. Die Ähnlichkeitsabfragen sind relativ, das heißt, es werden Ihnen zwar die ähnlichsten Wörter innerhalb des Korpus angezeigt, der Grad der Ähnlichkeit kann aber sehr unterschiedlich ausgeprägt sein. Wie hoch die Ähnlichkeit ist, können Sie anhand des Wertes ablesen, der hinter einem Wort angegeben ist. Diese Werte können sich im Bereich von +1 bis -1 befinden, einer Skala, die von sehr ähnlich (positiv, also +1) bis sehr unähnlich (negativ, also -1) erstreckt. \n",
    "\n",
    "Im nächsten Schritt fragen Sie das Modell nach den Wörtern, die in ähnlichen Kontexten verwendet werden wie \"gretchen\". Klicken Sie dazu unten in den Kasten, sodass Ihr Cursor dort erscheint. Klicken Sie dann auf \"Run\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e63ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "w1 = \"gretchen\"\n",
    "model.wv.most_similar (positive=w1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35bc8f7a",
   "metadata": {},
   "source": [
    "Nun schauen wir uns das Ganze noch mit dem Zielwort \"werther\" an. Klicken Sie wieder unten in den Kasten und klicken Sie dann auf \"Run\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d2db11",
   "metadata": {},
   "outputs": [],
   "source": [
    "w1 = \"werther\"\n",
    "model.wv.most_similar (positive=w1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7cd5c5b",
   "metadata": {},
   "source": [
    "Um noch ein konzeptuell ganz anderes Wort in den Fokus zu rücken, führen wir die gleiche Abfrage nun auch noch mit dem Zielwort \"liebe\" durch. Klicken Sie dazu wieder in den Kasten und dann auf \"Run\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32f7807b",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Aufgabe:</b> Vergleichen Sie die Ähnlichkeiteswerte von \"Gretchen\" und den ähnlichsten Wörtern und \"Werther\" und den ähnlichsten Wörtern. Was fällt Ihnen auf?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e04c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "w1 = \"liebe\"\n",
    "model.wv.most_similar (positive=w1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89cfd16f",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Aufgabe:</b> Schauen Sie sich die Wörter an, die in ähnlichen Kontexten wie \"liebe\" verwendet werden. Wie interpretieren Sie die Ergebnisse im Hinblick auf ein mögliches semantisches Feld der Liebe?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb1c4b52",
   "metadata": {},
   "source": [
    "### Vektorarithmetik\n",
    "\n",
    "Durch die Umrechnung von Wörtern in Vektoren, also in Zahlenwerte, bietet word2vec die einzigartige Möglichkeit, mit Wörtern zu rechnen. Sie können z.B. den Vektor eines Wortes von dem eines anderen Subtrahieren und dann Wörter anzeigen lassen, deren Vektor dem Ergebnis serh ähnlich ist. In untem stehenden Beispiel führen wir diese Vektorarithmetik mit den Wörtern Frau - Mann durch.\n",
    "\n",
    "Klicken Sie dazu in die Box unten und klicken Sie dann auf \"Run\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa849ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "w1 = ['frau']\n",
    "w2 = ['mann']\n",
    "model.wv.most_similar (positive=w1,negative=w2,topn=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dd13133",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Aufgabe:</b> Schauen Sie sich die Ähnlichkeitswerte hinter den Wörtern an. Was fällt Ihnen – im Hinblick auf ein semantisches Feld des Weiblichen – auf? \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fdfa8aa",
   "metadata": {},
   "source": [
    "Diese Vektorarithmetik funktioniert auch mit ganzen Wortgruppen. Indem eine ganze Gruppe von Wörtern zusammengefasst wird, ergibt sich ein semantisches Feld. Da für dieses semantische Feld mehr Daten im Modell enthalten sind, werden solche Abfragen häufig genauer als die Vektorarithmetik mit nur zwei Wörtern.\n",
    "\n",
    "Um mehr über die Konzeptionierung des Weiblichen bei Goethe herauszufinden, stellen wir eine Wortgruppe zusammen, die mehrere Frauenrollen umfasst. Dann subtrahieren wir \"Mann\" davon und erhalten kontextähnliche Wörter, die ebenfalls zum semantischen Feld des weiblichen beitragen.\n",
    "\n",
    "Um die Abfrage auszuführen, klicken Sie wieder in das Feld unten und dann auf \"Run\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f70873",
   "metadata": {},
   "outputs": [],
   "source": [
    "w1 = [\"frau\",'maedchen','mutter', 'tante','schwester']\n",
    "w2 = ['mann']\n",
    "model.wv.most_similar (positive=w1,negative=w2,topn=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e3f6dbf",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Aufgabe:</b> Bewerten Sie das Ergebnis im Vergleich zu der oben stehenden Abfrage mit nur zwei Wörtern!\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1eb1692",
   "metadata": {},
   "source": [
    "Auch die Gegenprobe kann interessant sein. Wenn Sie unten in das feld klicken und dann auf \"Run\", so wird eine Abfrage nach dem semantischen Feld des Männlichen durchgeführt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06023f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "w1 = [\"mann\",'junge','vater', 'onkel','bruder']\n",
    "w2 = ['frau']\n",
    "model.wv.most_similar (positive=w1,negative=w2,topn=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b9de7f",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Aufgabe:</b> Schauen Sie sich das Ergebnis im Vergleich mit der Abfrage, bei der die Wörter \"frau\", \"maedchen\",\"mutter\", \"tante\", \"schwester\" positiv und das Wort \"mann\" negativ mit einbezogen wurden. Was fällt Ihnen auf?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c81a54bd",
   "metadata": {},
   "source": [
    "### Ähnlichkeit zwischen zwei Wörtern bewerten\n",
    "\n",
    "Mithilfe Ihres word2vec-Modells können Sie – wie Sie nun bereits wissen – den Grad der Ähnlichkeit von Wörtern messen. Mit der nächsten Abfrage bekommen Sie den Wert der Ähnlichkeit zwischen wei Zielwörtern genannt. Klicken Sie dazu wieder unten in die Box und dann auf \"Run\".  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1225716e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.wv.similarity(w1=\"gretchen\",w2=\"kind\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00208a55",
   "metadata": {},
   "source": [
    "Nun wissen Sie welchen Ähnlichkeitswert Gretchen und Kind haben. Möchten Sie den Ähnlichkeitswert von Gretchen und Frau damit vergleichen, so führen Sie dieselbe Abfrage noch einmal wie folgt durch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9cfb90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.wv.similarity(w1=\"gretchen\",w2=\"frau\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b717ef",
   "metadata": {},
   "source": [
    "Natürlich darf auch die \"Gretchenfrage\" nicht fehlen. Dem word2vec-Modell können Sie sie auf diese Weise stellen: Wie ähnlich sind die Wortkontexte von \"Gretchen\" und \"Religion\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5420b06b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.wv.similarity(w1=\"gretchen\",w2=\"religion\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f25ae01e",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Aufgabe:</b> \"Gretchen\" und \"Kind\", \"Frau\" oder \"Religion\", welche beiden Wörter werden am ähnlichsten verwendet?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef5d34eb",
   "metadata": {},
   "source": [
    "## Das Modell prüfen\n",
    "\n",
    "Es gibt ein paar simple Wege, um zu prüfen, ob Ihr Modell tatsächlich Wörter zusammen gruppiert, die einem sinnvollen semantischen Feld zugeordnet werden können. Eine Methode dafür entspricht dem \"eins von diesen Dingen gehört nicht zu den anderen\"-Prinzip. Sie nennen dem Modell eine Reihe von Wörtern und zurück kommt eine Antwort auf die Frage, welches Wort in der Reihe nicht zu den anderen gehört. \n",
    "\n",
    "Um diese Prüfung zu starten, klicken Sie wieder in die Box unten, sodass Ihr Cursor dort erscheint und dann oben auf \"Run\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d3935a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.wv.doesnt_match([\"mann\",\"krieger\",\"soldat\",\"kind\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42de295a",
   "metadata": {},
   "source": [
    "## Das Modell visualisieren\n",
    "\n",
    "Sie haben nun ein word2vec-Modell erstellt, einige Abfragen kennen gelernt und geprüft, ob das Modell sinnvolle semantische Felder ausmachen kann. Um Ihnen noch eine weitere Perspektive aug Ihr Modell zu zeigen, führen wir nun noch zwei grundlegende Formen der Visualisierung des word2vec-Modells durch. Bei beiden wird eine Reduktion der Dimensionen des Modells auf ein zweidimensionales Koordinatensystem durchgeführt. Dazu wird eine Methode namens t-SNE genutzt (mehr darüber in Schumacher und Uglanova 2022: https://fortext.net/routinen/methoden/word2vec)Innerhalb dieses Koordinatensystems werden die Wörter im Korpus dargestellt. Nah beieinander stehende Wörter werden in ähnlichen Kontexten verwendet, weit voneinander entfernt stehende Wörter gehören nicht zu einem ähnlichen semantischen Feld. Wir werden nun zunächst das gesamte Modell visualisieren und dann nur einzelne semantische Felder.\n",
    "\n",
    "### Das gesamte word2vec-Modell visualisieren\n",
    "\n",
    "Um das gesamte word2vec-Modell zu visualisieren, klicken Sie unten in die Box, sodass Ihr Cursor darin erscheint und klicken Sie dann oben im Menü auf \"Run\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0488171",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import IncrementalPCA  \n",
    "from sklearn.manifold import TSNE                  \n",
    "import numpy as np                                 \n",
    "\n",
    "\n",
    "def reduce_dimensions(model):\n",
    "    num_dimensions = 2  # Hier ist die Nummer der Dimensionen eingetragen (2D, 3D, etc)\n",
    "\n",
    "    # Vektoren und Wörter aus Ihrem Modell werden geladen\n",
    "    vectors = np.asarray(model.wv.vectors)\n",
    "    labels = np.asarray(model.wv.index_to_key)  # fixed-width numpy strings\n",
    "\n",
    "    # Komplexitätsreduktion mit t-SNE\n",
    "    tsne = TSNE(n_components=num_dimensions, random_state=0)\n",
    "    vectors = tsne.fit_transform(vectors)\n",
    "\n",
    "    x_vals = [v[0] for v in vectors]\n",
    "    y_vals = [v[1] for v in vectors]\n",
    "    return x_vals, y_vals, labels\n",
    "\n",
    "\n",
    "x_vals, y_vals, labels = reduce_dimensions(model)\n",
    "\n",
    "def plot_with_plotly(x_vals, y_vals, labels, plot_in_notebook=True):\n",
    "    from plotly.offline import init_notebook_mode, iplot, plot\n",
    "    import plotly.graph_objs as go\n",
    "\n",
    "    trace = go.Scatter(x=x_vals, y=y_vals, mode='text', text=labels)\n",
    "    data = [trace]\n",
    "\n",
    "    if plot_in_notebook:\n",
    "        init_notebook_mode(connected=True)\n",
    "        iplot(data, filename='word-embedding-plot')\n",
    "    else:\n",
    "        plot(data, filename='word-embedding-plot.html')\n",
    "\n",
    "\n",
    "def plot_with_matplotlib(x_vals, y_vals, labels):\n",
    "    import matplotlib.pyplot as plt\n",
    "    import random\n",
    "\n",
    "    random.seed(0)\n",
    "\n",
    "    plt.figure(figsize=(12, 12))\n",
    "    plt.scatter(x_vals, y_vals)\n",
    "\n",
    "    indices = list(range(len(labels)))\n",
    "    selected_indices = random.sample(indices, 25)\n",
    "    for i in selected_indices:\n",
    "        plt.annotate(labels[i], (x_vals[i], y_vals[i]))\n",
    "try:\n",
    "    get_ipython()\n",
    "except Exception:\n",
    "    plot_function = plot_with_matplotlib\n",
    "else:\n",
    "    plot_function = plot_with_plotly\n",
    "\n",
    "plot_function(x_vals, y_vals, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e220a66",
   "metadata": {},
   "source": [
    "### Einzelne semantische Felder visualisieren\n",
    "\n",
    "Bei der nächsten Form der Visualsierung können Sie einzelne semantische Felder in unterschiedlichen Farben anzeigen lassen. Für unser Fallbeispiel betrachten wir die Begriffe \"Frau\" und \"Mann\". Die Graphik, die erstellt wird, hat den Titel \"Genderdarstellungen bei Goethe\" und wird unter dem Namen \"Gender_Goethe.png\" auf Ihrem Computer gespeichert. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8d160a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "\n",
    "keys = ['frau', 'mann']\n",
    "\n",
    "embedding_clusters = []\n",
    "word_clusters = []\n",
    "for word in keys:\n",
    "    embeddings = []\n",
    "    words = []\n",
    "    for similar_word, _ in model.wv.most_similar(word, topn=30):\n",
    "        words.append(similar_word)\n",
    "        embeddings.append(model.wv[similar_word])\n",
    "    embedding_clusters.append(embeddings)\n",
    "    word_clusters.append(words)\n",
    "    \n",
    "from sklearn.manifold import TSNE\n",
    "import numpy as np\n",
    "\n",
    "embedding_clusters = np.array(embedding_clusters)\n",
    "n, m, k = embedding_clusters.shape\n",
    "tsne_model_en_2d = TSNE(perplexity=15, n_components=2, init='pca', n_iter=3500, random_state=32)\n",
    "embeddings_en_2d = np.array(tsne_model_en_2d.fit_transform(embedding_clusters.reshape(n * m, k))).reshape(n, m, 2)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "\n",
    "def tsne_plot_similar_words(title, labels, embedding_clusters, word_clusters, a, filename=None):\n",
    "    plt.figure(figsize=(16, 9))\n",
    "    colors = cm.rainbow(np.linspace(0, 1, len(labels)))\n",
    "    for label, embeddings, words, color in zip(labels, embedding_clusters, word_clusters, colors):\n",
    "        x = embeddings[:, 0]\n",
    "        y = embeddings[:, 1]\n",
    "        plt.scatter(x, y, c=color, alpha=a, label=label)\n",
    "        for i, word in enumerate(words):\n",
    "            plt.annotate(word, alpha=0.5, xy=(x[i], y[i]), xytext=(5, 2),\n",
    "                         textcoords='offset points', ha='right', va='bottom', size=8)\n",
    "    plt.legend(loc=4)\n",
    "    plt.title(title)\n",
    "    plt.grid(True)\n",
    "    if filename:\n",
    "        plt.savefig(filename, format='png', dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "tsne_plot_similar_words('Genderdarstellungen bei Goethe', keys, embeddings_en_2d, word_clusters, 0.7,\n",
    "                        'Gender_Goethe.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d59dd5",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Aufgabe:</b> Schauen Sie sich die Visualsierung der semantischen Felder der Wörter \"Frau\" und \"Mann\" an. Ist die Zuweisung, die im word2vec-Modell festgelegt ist akkurat?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104abcac",
   "metadata": {},
   "source": [
    "## Eigene Abfragen erstellen\n",
    "\n",
    "Sie kennen nun einige grundlegende Aspekte des Workflows der word2vec-Methode. Auf Basis dieses Ablaufs können Sie nun eigene Daten nutzen und eigene Abfragen erstellen. Ändern Sie einfach den Dateipfad in Schritt 3, um ein eigenes Korpus zu einem word2vec-Modell umrechnen zu lassen. Tauschen Sie die Begriffe in den Abfragen durch solche aus, die Sie interessieren. In der zuletzt angelegten Visualisierung können Sie die Begriffe in der Zeile\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "keys = ['frau', 'mann']\n",
    "</div>\n",
    "\n",
    "austauschen. Außerdem können Sie in der letzten Zeile den Titel der Visualisierung und den Dateinamen zum Abspeichern verändern. Klicken Sie dazu einfach in die Box, markieren die Textstelle, die sie austauschen wollen und geben Sie etwas Neues ein."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e32c545b",
   "metadata": {},
   "source": [
    "## Schlussbemerkungen\n",
    "\n",
    "In dieser Lerneinheit haben wir ein word2vec-Modell anhand eines relativ kleinen Korpus (Goethes Prosatexte und Dramen, insgesamt 45 Werke) trainiert, Abfragen erstellt und Visualisierungen angefertigt. Solche Modelle nehmen deutlich an Qualität zu, wenn größere Datenmengen zugrunde gelegt werden. Mehr über die methodischen Grundlagen erfahren Sie in unserem Methodenbeitrag word2vec (Schumacher und Uglanova 2022: https://fortext.net/routinen/methoden/word2vec). \n",
    "\n",
    "Die Lösungen zu den hier aufgeführten Beispielaufgaben sowie Hinweise dazu, wie Sie ein Korpus vorbereiten sollten, wenn Sie es für word2vec mit Gensim nutzen wollen, finden Sie in unserer word2vec-Lerneinheit (Schumacher 2022: https://fortext.net/routinen/lerneinheiten/word2vec-mit-gensim)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
